# -*- coding: utf-8 -*-
"""NgoTheTu_LW1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12axqdgFc8r9cP08o1sAjQxw9un82V7lc

Numba + CUDA on Google Colab
"""

!pip install pynvml

import numba
from numba import cuda

numba.cuda.detect()

numba.cuda.select_device(0)

numba.cuda.close()
numba.cuda.gpus

from numba.cuda.cudadrv import enums
from numba import cuda
import numpy as np
device = cuda.get_current_device()
attribs= [name.replace("CU_DEVICE_ATTRIBUTE_", "") for name in dir(enums) if name.startswith("CU_DEVICE_ATTRIBUTE_")]
print(np.array(attribs))
atrr_s = ['MULTIPROCESSOR_COUNT', 'TOTAL_CONSTANT_MEMORY', 'MAX_SHARED_MEMORY_PER_MULTIPROCESSOR']
for attr in attribs:
  if attr in atrr_s:
    print(attr, '=', getattr(device, attr))

print('Device Name : ', (cuda.select_device(0)))



print('Multiprocessor-count :', getattr(device,'MULTIPROCESSOR_COUNT'))

print('Clock_rate :' , getattr(device,'CLOCK_RATE'))

print('Toltal-constant-memory :',getattr(device,'TOTAL_CONSTANT_MEMORY'))

from pynvml import *
nvmlInit()
h = nvmlDeviceGetHandleByIndex(0)
info = nvmlDeviceGetMemoryInfo(h)
print(f'total Memory   : {info.total}')
print(f'free Memory   : {info.free}')
print(f'used Memory   : {info.used}')